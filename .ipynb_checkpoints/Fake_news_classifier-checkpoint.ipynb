{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/maleepicface/brianhelenfakenews/blob/main/Fake_news_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "WKuh8-U5ckKt"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timer code\n",
    "    # import timeT\n",
    "    # tic = time.perf_counter()                                     add this in the beginning of the CNN\n",
    "    # toc = time.perf_counter()                                     add this at the end of the code\n",
    "    # print (f\"Finished running in {toc - tic: 0.2f} seconds\")      add after the toc command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print  (\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function list_physical_devices at 0x000001C3B8284E50>\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8603739236770523527\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2907098318\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7282919158157616918\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>The lie that coronavirus came from a bat or a ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>The health experts had predicted the virus cou...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F</td>\n",
       "      <td>The Centers for Disease Control and Prevention...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>U</td>\n",
       "      <td>Warm weather will kill coronavirus. U.S. Presi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>F</td>\n",
       "      <td>Using a hair dryer to breathe in hot air can c...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                              title number\n",
       "3       F  The lie that coronavirus came from a bat or a ...      3\n",
       "4       F  The health experts had predicted the virus cou...      3\n",
       "8       F  The Centers for Disease Control and Prevention...      3\n",
       "10      U  Warm weather will kill coronavirus. U.S. Presi...      2\n",
       "15      F  Using a hair dryer to breathe in hot air can c...      2"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"C:/Users/bliu0/Documents/GitHub/COVID-19-rumor-dataset/Data/news/news.csv\", names = [\"rating\", \"title\", \"number\"])\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     rating                                              title\n",
      "3         F  The lie that coronavirus came from a bat or a ...\n",
      "4         F  The health experts had predicted the virus cou...\n",
      "8         F  The Centers for Disease Control and Prevention...\n",
      "10        U  Warm weather will kill coronavirus. U.S. Presi...\n",
      "15        F  Using a hair dryer to breathe in hot air can c...\n",
      "...     ...                                                ...\n",
      "4197      F  “[The coronavirus is] “new” yet it was lab-cre...\n",
      "4199      F  A post claims that you have to wear a disposab...\n",
      "4202      F  Clickbait / Russian scientists have a cure for...\n",
      "4203      F         Coronavirus outbreak linked to eating bats\n",
      "4207      F  A chain message circulated on Tuesday, January...\n",
      "\n",
      "[4129 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bliu0\\AppData\\Local\\Temp/ipykernel_13608/1043144753.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  test = test.drop('number', 1)\n"
     ]
    }
   ],
   "source": [
    "test = test.drop('number', 1)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F             3041\n",
       "T              659\n",
       "U              428\n",
       "U(Twitter)       1\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv1d kernel size = 128 x 5 \n",
    "# LSTM kernel size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='rating', ylabel='count'>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(x='rating', data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [d.split() for d in test['title'].tolist()]\n",
    "y = test['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4129\n"
     ]
    }
   ],
   "source": [
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 4129\n",
    "w2v_model = gensim.models.Word2Vec(sentences=x, size=DIM, window=10, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13702"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'march' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13608/3755979238.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mw2v_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'march'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    551\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[1;34m(self, word, use_norm)\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"word 'march' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(['march'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tokenizer.texts_to_sequences(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(a) for a in x], bins = 700)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos = np.array([len(a) for a in x])\n",
    "len(nos[nos>1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 1000\n",
    "x = tf.keras.preprocessing.sequence.pad_sequences(x, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_matrix(model):\n",
    "    weight_matrix = np.zeros((vocab_size, DIM))\n",
    "    \n",
    "    for word, i in vocab.items():\n",
    "        try:\n",
    "            weight_matrix[i] = model.wv[word]\n",
    "        except:\n",
    "            print(\"whatever\")\n",
    "        \n",
    "    return weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n",
      "whatever\n"
     ]
    }
   ],
   "source": [
    "embedding_vectors = get_weight_matrix(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12149, 4129)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot convert a symbolic Tensor (lstm_1/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13608/2876163175.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDIM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0membedding_vectors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    226\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 969\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    970\u001b[0m                                                 input_list)\n\u001b[0;32m    971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1105\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[0;32m   1106\u001b[0m       \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1108\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[0;32m   1109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    838\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    878\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m           \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m     \u001b[1;31m# LSTM does not support constants. Ignore it during process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1153\u001b[1;33m     \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(self, inputs, initial_state, constants)\u001b[0m\n\u001b[0;32m    866\u001b[0m         \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m       \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mget_initial_state_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m       init_state = get_initial_state_fn(\n\u001b[0m\u001b[0;32m    651\u001b[0m           inputs=None, batch_size=batch_size, dtype=dtype)\n\u001b[0;32m    652\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[1;34m(self, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2515\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2516\u001b[1;33m     return list(_generate_zero_filled_state_for_cell(\n\u001b[0m\u001b[0;32m   2517\u001b[0m         self, inputs, batch_size, dtype))\n\u001b[0;32m   2518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state_for_cell\u001b[1;34m(cell, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2996\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2997\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2998\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_generate_zero_filled_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state\u001b[1;34m(batch_size_tensor, state_size, dtype)\u001b[0m\n\u001b[0;32m   3012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3013\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_nested\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3014\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_zeros\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3015\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3016\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_zeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mcreate_zeros\u001b[1;34m(unnested_state_size)\u001b[0m\n\u001b[0;32m   3009\u001b[0m     \u001b[0mflat_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munnested_state_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3010\u001b[0m     \u001b[0minit_state_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_size_tensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mflat_dims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3011\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_state_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3013\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_nested\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2910\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2911\u001b[1;33m     \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2912\u001b[0m     \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_zeros_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2913\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mzeros\u001b[1;34m(shape, dtype, name)\u001b[0m\n\u001b[0;32m   2958\u001b[0m           \u001b[1;31m# Create a constant if it won't be very big. Otherwise create a fill\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2959\u001b[0m           \u001b[1;31m# op to prevent serialized GraphDefs from becoming too large.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2960\u001b[1;33m           \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2961\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2962\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_constant_if_small\u001b[1;34m(value, shape, dtype, name)\u001b[0m\n\u001b[0;32m   2894\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2895\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2896\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2897\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3050\u001b[0m     \"\"\"\n\u001b[1;32m-> 3051\u001b[1;33m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0m\u001b[0;32m   3052\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0;32m   3053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m     raise NotImplementedError(\n\u001b[0m\u001b[0;32m    868\u001b[0m         \u001b[1;34m\"Cannot convert a symbolic Tensor ({}) to a numpy array.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[1;34m\" This error may indicate that you're trying to pass a Tensor to\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (lstm_1/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, output_dim=DIM, weights=[embedding_vectors], input_length=maxlen, trainable = False))\n",
    "model.add(tf.keras.layers.LSTM(units=100))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, validation_split=0.3, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Fake news classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
